{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet No. 3\n",
    "\n",
    "---\n",
    "\n",
    "> Machine Learning for Natural Sciences, Summer 2021, Jun.-Prof. Pascal Friederich, pascal.friederich@kit.edu\n",
    "> \n",
    "> Deadline: 03.05.2021, 2pm\n",
    "\n",
    "---\n",
    "\n",
    "**Topic**: This exercise sheet will focus on linear algebra, precision, recall and feature reduction. You will continue to use ``numpy`` methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Distance function computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many feature descriptors and also for a specific implementation of the nearest neighbor classier, the Euclidean mutual distance between a set of points must be computed. This serves as a measure on how two points are distinct or how far apart they are in Euclidean space. We will make use of this very often in the future. Therefore this exercise focus on an efficient implementation using numpy. You should gain a better unstanding of `numpy` methods.\n",
    "\n",
    "**3.1.1** Implement this in a python function ``dist_loop(A,B)``, which computes the Euclidean distance between all instances between two sets of points $A \\subset \\mathbb{R}^{D}$ and $B \\subset \\mathbb{R}^{D}$. The input should be two matrices of shape $N \\times D$ and $M \\times D$. Do this by using explicit python loops to find the distance $d_{ij} = || a_{i} - b_{j} ||$ between two points $a_{i} \\in A$ and $b_{i} \\in B$. The output should be a $N \\times M$ distance matrix. For the calculation of the Euclidean distance you might want to use ``numpy.square()``, ``numpy.sum()`` and ``numpy.sqrt()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A shape: (500, 3) B shape: (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import sys\n",
    "n = 500\n",
    "m = 1000\n",
    "d = 3\n",
    "A_data = np.reshape(random.rand(n*d),(n,d))\n",
    "B_data = np.reshape(random.rand(m*d),(m,d))\n",
    "print(\"A shape:\", A_data.shape, \"B shape:\", B_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "780ba4623e3885a960819a4cd554ca9b",
     "grade": false,
     "grade_id": "dist_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dist_loop(A,B):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.2** Since loops are rather slow in python, and more efficient code is required for numeric operations, write a second\n",
    "python function ``dist_vec(A,B)`` for computing the distance function which relies\n",
    "on vectorization from ``numpy`` methods. Consult https://www.safaribooksonline.com/library/view/python-for-data/9781449323592/ch04.html and https://softwareengineering.stackexchange.com/questions/254475/how-do-i-move-away-from-the-for-loop-school-of-thought for information on how to do this. \n",
    "\n",
    "Tip: There is more than one way to do it. For the most straightforward answer, you need to add an additional dimension to `np.arrays` via for example `expand_dims`. If two `np.arrays` do not have matching shape they are then automatically broadcasted by repeating their respective element along the axis in question. Beside broadcasting, also the [indexing rules](https://numpy.org/doc/stable/reference/arrays.indexing.html) (required for 3.2, 3.3) of `numpy` help with vectorization to avoid pyhton loops. You must not use ``scipy`` or its methods for this task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c528a8f299889fc60698e8e2ca273aad",
     "grade": false,
     "grade_id": "dist_vec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dist_vec(A,B):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the two function return the same result. And check the output shape of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4b043d946187d5d4b08030dc999dd25",
     "grade": false,
     "grade_id": "difference_dist",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "result_loop = dist_loop(A_data,B_data)\n",
    "result_vec = dist_vec(A_data,B_data)\n",
    "result_vec_shape = None # Check shape of result_loop\n",
    "result_loop_shape = None # Check shape of result_vec\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare the run times of the two implementations using jupyter's ``%timeit`` command or pythons ``time``. How much faster is the vectorized version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure time for loop\n",
    "%timeit result_loop = dist_loop(A_data,B_data)\n",
    "# measure time for loop\n",
    "%timeit result_vec = dist_vec(A_data,B_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b24b19b8a3cbe955f59b06db7827d968",
     "grade": false,
     "grade_id": "speed_up",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "speed_up_factor = 1 # A rough estimation is okay.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: It is absolutely critical that you understand vectorization, and with this the indexing and broadcasting methods of numy. Not only do we need the fast performance, but also all deep learning frameworks are based on array or tensor operations just like you used with ``numpy``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d345427c278908d66a6e8c001fb2661",
     "grade": true,
     "grade_id": "test_funs_1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert callable(dist_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05643463f89fd50e041bf163fdca4b47",
     "grade": true,
     "grade_id": "test_funs_2",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert callable(dist_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "459df0926156337be62aaea0c5c075cf",
     "grade": true,
     "grade_id": "test_loop_diff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert result_loop is not None\n",
    "assert result_vec is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c6c6b013eac1bb0f4bca02179c6d58e",
     "grade": true,
     "grade_id": "test_shape_dist",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert result_vec_shape is not None\n",
    "assert result_loop_shape is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a73fc69bd5b9e328d85dabfc9a8d011b",
     "grade": true,
     "grade_id": "speed_up_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert speed_up_factor > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we use sklearn's digits dataset for an image retrieval experiment. Given any image\n",
    "from this dataset as a query, your algorithm shall find all similar images, where we define similarity\n",
    "by \"contains the same digit\". Of course, only the features (i.e. the pixel values of the images) may be\n",
    "used for similarity search. The known labels only serve for testing the quality of the search result. This approach measures how clustered the calsses are in a defined feature space (i.e. pixels). Start loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read and prepare the digits data\n",
    "digits = load_digits()\n",
    "data = digits[\"data\"]\n",
    "images = digits[\"images\"]\n",
    "target = digits[\"target\"]\n",
    "# Show digits\n",
    "fig = plt.figure(figsize = (10,3))\n",
    "plt.gray()\n",
    "plt.subplot(1,3,1); plt.axis('off')\n",
    "plt.imshow(images[0])\n",
    "plt.subplot(1,3,2); plt.axis('off')\n",
    "plt.imshow(images[1])\n",
    "plt.subplot(1,3,3); plt.axis('off')\n",
    "plt.imshow(images[2])\n",
    "fig.tight_layout(); plt.show()\n",
    "print(target[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dissimilarity by the Euclidean distance between pixel values:\n",
    "\n",
    "$d(X_i,X_{i'} ) = || X_i - X_{i'}||^2_2$\n",
    "\n",
    "To effciently compute these distances, you should use vectorization from exercise 3.1. Let $D$\n",
    "be the full dissimilarity matrix, i.e. $D_{i i'} = d(X_i,X_{i'})$. An ``np.argsort()`` of row $D_i$ now gives the similarity ordering of all digits relative to query digit $X_i$. The response sets $S_{im}$ consist of the $m$ nearest instances to query $X_i$ (including $X_i$ itself), with $m$ running over all values from 1 to $N$.\n",
    "\n",
    "Note: If you didn't manage to solve 3.1 you can now use `scipy.spatial.distance.cdist`. But you do not get points for this solution in 3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "edc9d1a38d723910c8a7f26f999a1781",
     "grade": false,
     "grade_id": "sort_Sim",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dist_xx = None # Compute distance matrix from data (data = digits[\"data\"]), do not change the data here!\n",
    "resp_Sim = None # Response set that holds indices (i,m) for X_i-X_m\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positive class is defined by the instances having the same label as the query, i.e. $Y_{i'} = Y_i$, and\n",
    "$N_i = \\# \\{i' \\in 1,\\dots,N : Y_{i'} = Y_i \\}$ is the total number of positives. Each response set defines a pair ($\\text{precision}_{im}$; $\\text{recall}_{im}$) as:\n",
    "\n",
    "$\\text{precision}_{im} = \\frac{\\text{TP}_i(m)}{\\text{TP}_i(m) + \\text{FP}_i(m)}$,      $\\text{recall}_{im} = \\frac{\\text{TP}_i(m)}{N_i}$\n",
    "\n",
    "where $\\text{TP}_i(m) = \\# \\{i' \\in S_{im} : Y_i = Y_{i'}\\}$ and $\\text{FP}_i(m) = \\# \\{i' \\in S_{im} : Y_i \\neq Y_{i'}\\}$ are the number of true and false positives in $S_{im}$. Compute the $N\\times N$ precision matrix $P$ and recall matrix $R$ whose elements are the precision resp. recall values from these pairs, i.e. $P_{im} = \\text{precision}_{im}$ and $R_{im} = \\text{recall}_{im}$. \n",
    "\n",
    "Tip: You can use broadcasting with `np.expand_dims(axis)` and `np.cumsum` for vectorization. You may use indexing and indexing via boolean arrays, too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9ed3362f91b34672a78a83856d87a2a",
     "grade": false,
     "grade_id": "true_false_positives",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "true_positives = None # as TP_i(m) of shape (1797, 1797)\n",
    "false_positives = None #  as FP_i(m) of shape (1797, 1797)\n",
    "total_positives = None # as N_i of shape (1797,)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# Calculate the NxN precision and recall matrices\n",
    "Pim = None # of shape (1797, 1797)\n",
    "Rim = None # of shape (1797, 1797)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each digit class $k \\in \\{0,\\dots,9\\}$, compute $\\bar{P}_k$ and $\\bar{R}_k$ as the average of the rows of $P$ and $R$ referring to class $k$, i.e. where $Y_i = k$, with $m$ as the the free parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30f61b2e6026e40fc9a0081b52ad1bb5",
     "grade": false,
     "grade_id": "avg_PR",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Pk_m = None # averaged Pim of shape (10,1797)\n",
    "Rk_m = None # averaged Rim of shape (10,1797)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the resulting precision/recall curves (using $m$ as the free parameter) and determine the area-under-curve (AUC) for each $k$. Do not use the implementation of ``sklearn`` in this task. This means you have to plot Recall vs. Precision for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b67dd0082177fd4ebf47f5d275c7a3c5",
     "grade": false,
     "grade_id": "AUC",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def auc_precision_recall(precision,recall):\n",
    "    # precision is P(m) for a specific class of shape (1797,)\n",
    "    # recall is R(m) for a specific class of shape (1797,)\n",
    "    return np.abs(np.trapz(y=precision, x=(recall)))\n",
    "# Get Area under curve with auc_precision_recall()\n",
    "AUC = None # List of AUC for each number 0,...,9 via auc_precision_recall()\n",
    "\n",
    "# Plot the Precision-Recall Curves\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da51b2ae1bdef05b9aa2a1133beb734e",
     "grade": true,
     "grade_id": "test_dist_digit_1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert dist_xx is not None\n",
    "assert dist_xx.shape[0] == 1797 and dist_xx.shape[1] == 1797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a0ae3fba6603ccff3efa85ecd69d5c8",
     "grade": true,
     "grade_id": "test_dist_digit_2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert resp_Sim is not None\n",
    "try:\n",
    "    assert np.all(resp_Sim[0:2,0:2] == np.array([[0,877],[1,93]]))\n",
    "except:\n",
    "    print(\"resp_Sim should contain indices that give a similarity ordering, please do not shuffle the data for grading tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cf1e7c6ed744f4218c81b26f67ec42e",
     "grade": true,
     "grade_id": "test_po_neg_true",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert true_positives is not None\n",
    "try:\n",
    "    assert true_positives[0,0] == 1 and true_positives[0,-1] == 178\n",
    "except:\n",
    "    print(\"As a sanity test, the first entry should be always 1 and the lasts equals the number of class labels for that digit.\")\n",
    "    print(\"Number of 0's:\", np.sum(target == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d3fb47627be2304f01f0213d6a4df65",
     "grade": true,
     "grade_id": "test_po_neg_false",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert false_positives is not None\n",
    "try:\n",
    "    assert false_positives[0,0] == 0 and false_positives[0,-1] == 1619\n",
    "except:\n",
    "    print(\"As a sanity test, the first entry should be always 0 and the last equals the number of other class labels for that digit.\")\n",
    "    print(\"Number of classes;\",len(target) ,\"number of 0's:\", np.sum(target == 0), \"means: \", len(target) - np.sum(target == 0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4961158916c2621ba8e8578003e61fa",
     "grade": true,
     "grade_id": "test_po_neg_total",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert total_positives is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "534f795de2464133c8f1abea3aaf3add",
     "grade": true,
     "grade_id": "test_Pim",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert Pim is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53184c0b34ee202559d937319b5c9b22",
     "grade": true,
     "grade_id": "test_Rim",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert Rim is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15427d527db52cbe7508dc51d199d9f6",
     "grade": true,
     "grade_id": "test_Pk",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert Pk_m is not None\n",
    "try:\n",
    "    assert Pk_m[0,0] - 1 < 0.01 and Pk_m[0,-1] - 0.09905 < 0.01\n",
    "except:\n",
    "    print(\"For closest neighbours we expect high precision, and low precision for all neighbours considered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b96828d807bf22e44cc6412293c0995",
     "grade": true,
     "grade_id": "test_Rk",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert Rk_m is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97e63b3461cea7646b2ead050eaf29c7",
     "grade": true,
     "grade_id": "test_auc",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert AUC is not None\n",
    "try:\n",
    "    assert (AUC[0] - 0.9450) < 0.1 and (AUC[-1] - 0.4825) < 0.1\n",
    "except:\n",
    "    print(\"We expect a bad AUC for similar digits like 9,8,6. Interestingly '0' is well clustered with AUC of ca. 0.95\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 PCA and LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to reduce the number of features or pixels to two and re-test the precision/recall curves from exercise 3.2.\n",
    "\n",
    "As a first approach we try an unsupervised reduction of features, namely via Principle Component Analysis (PCA). The task is to use `scikit-learn`'s implementation of the PCA to reduce the number of pixels to two and then to make a scatter plot of the new features, where the color of each point represents the digits number.  Which property should this scatterplot have in order for the new features to be especially suitable for similarity search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b338b8dfadeacab31b4eda91cbe63f3",
     "grade": false,
     "grade_id": "PCA",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "new_features_pca = None # Make new features of shape (1797, 2)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the experiment from above for new features but this time with a supervised feature reduction. We use the Linear Discriminant Analysis (LDA), which is linear too but seeks to fit class conditional densities to the data and using Bayesâ€™ rule. You can use the `scikit-learn`'s implementation of LDA. Repeat the step above and make a scatter plot of the new features, where the color of each point represents the digits number. What is the difference? Which method is better suited for dissimilarity search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66f378703c5300d21acf4de223af5684",
     "grade": false,
     "grade_id": "LDA",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "new_features_lda = None # Make new features of shape (1797, 2)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have to repeat the steps of 3.2. To do so, simply wrap the solution of 3.2 in a function as indicated below.\n",
    "\n",
    "Note: If you didn't solve 3.2, you can still answer the question based the plots above. The function below and the PCA/LDA recall curves are not graded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb42c15c5700aa1d6e8dcdd38738aa3f",
     "grade": true,
     "grade_id": "cell-ffb452aa6e6575b6",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def make_precision_recall_distance(data,target):\n",
    "    # return Pk_m, Rk_m\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the precision-recall curves for the dissimilarity by the Euclidean distance of the new features for the PCA and LDA. What do you observe? Does it improve with respect to the full digits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84811c83cabe903d08fe67fbc94210bb",
     "grade": false,
     "grade_id": "improve",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "linear_reduction_answer = None # Get better: True , get worse: False\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84928f19a3ef1bdbf942e50d8f2ef5a2",
     "grade": true,
     "grade_id": "test_PCA",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert new_features_pca is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b609efb6f0ecbb62e5f3a75a795cc706",
     "grade": true,
     "grade_id": "test_LDA",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert new_features_lda is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e0167887a37a14d8ebce1ef3f9f4d1d",
     "grade": true,
     "grade_id": "test_PCA_LDA_Recall",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(linear_reduction_answer,bool)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
